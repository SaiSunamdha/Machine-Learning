{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = {'x1':[0.346, 0.303, 0.358, 0.602, 0.790, 0.611],\n",
    "         'x2':[0.780, 0.439, 0.729, 0.863, 0.753, 0.965],\n",
    "         'y' :[0, 0, 0, 1, 1, 1]}\n",
    "  \n",
    "te = {'x1':[0.959, 0.750, 0.395, 0.823, 0.761, 0.844],\n",
    "         'x2':[0.382, 0.306, 0.760, 0.764, 0.874, 0.435],\n",
    "         'y' :[0, 0, 0, 1, 1, 1]}\n",
    "# Create DataFrame\n",
    "Train = pd.DataFrame(tr)\n",
    "Test = pd.DataFrame(te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_Train=Train.iloc[:,:-1].values\n",
    "y_Train=Train.iloc[:,-1:].values\n",
    "\n",
    "\n",
    "x_Test=Test.iloc[:,:-1].values\n",
    "y_Test=Test.iloc[:,-1:].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.346, 0.78 ],\n",
       "       [0.303, 0.439],\n",
       "       [0.358, 0.729],\n",
       "       [0.602, 0.863],\n",
       "       [0.79 , 0.753],\n",
       "       [0.611, 0.965]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.959, 0.382],\n",
       "       [0.75 , 0.306],\n",
       "       [0.395, 0.76 ],\n",
       "       [0.823, 0.764],\n",
       "       [0.761, 0.874],\n",
       "       [0.844, 0.435]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-a) (3 marks) Implement your own code for a logistic regression classifier, which is trained using gradient descent and cross-entropy error as the error function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(result):\n",
    "    FinalResult = 1/(1+np.exp(-result))\n",
    "    return FinalResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Intialization_of_weight(n_features):\n",
    "    w = np.zeros((1,n_features))\n",
    "    b = 0\n",
    "    return w,b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Optimization(w, b, X, Y):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    FinalResult = Sigmoid(np.dot(w,X.T)+b)\n",
    "    Y_T = Y.T\n",
    "    cost = (-1/m)*(np.sum((Y_T*np.log(FinalResult)) + ((1-Y_T)*(np.log(1-FinalResult)))))\n",
    "   \n",
    "    \n",
    "    dw = (1/m)*(np.dot(X.T, (FinalResult-Y.T).T))\n",
    "    db = (1/m)*(np.sum(FinalResult-Y.T))\n",
    "    \n",
    "    gradients = {\"dw\": dw, \"db\": db}\n",
    "    \n",
    "    return gradients, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Model_Prediction(w, b, X, Y, learning_rate, no_iterations):\n",
    "    costs = []\n",
    "    W=[]\n",
    "    for k in range(no_iterations):\n",
    "        \n",
    "        grads, cost = Optimization(w,b,X,Y)\n",
    "        \n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # updating the weights :\n",
    "        \n",
    "        w = w - (learning_rate * (dw.T))\n",
    "        b = b - (learning_rate * db)\n",
    "        \n",
    "        if (k % 100 == 0):\n",
    "            costs.append(cost)\n",
    "            W.append(w[0][0])\n",
    "    coefficient = {\"w\": w, \"b\": b}\n",
    "    gradient = {\"dw\": dw, \"db\": db}\n",
    "    \n",
    "    return coefficient, gradient, costs,W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(final_Prediction, m):\n",
    "    y_Prediction = np.zeros((1,m))\n",
    "    for Z in range(final_Prediction.shape[1]):\n",
    "        if final_Prediction[0][Z] > 0.5:\n",
    "            y_Prediction[0][Z] = 1\n",
    "    return y_Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized weights [[2.16160425 0.71079827]]\n",
      "Optimized intercept -1.4763538244350112\n",
      "Train Accuracy 1.0\n",
      "Test Accuracy 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "n_features = x_Train.shape[1]\n",
    "\n",
    "w, b = Intialization_of_weight(n_features)\n",
    "\n",
    "\n",
    "coefficient, gradient, costs,W = Model_Prediction(w, b, x_Train, y_Train, learning_rate=0.1,no_iterations=400)\n",
    "\n",
    "\n",
    "w = coefficient[\"w\"]\n",
    "b = coefficient[\"b\"]\n",
    "\n",
    "print('Optimized weights', w)\n",
    "print('Optimized intercept',b)\n",
    "\n",
    "final_Train_Prediction = Sigmoid(np.dot(w,x_Train.T)+b)\n",
    "final_Test_Prediction = Sigmoid(np.dot(w,x_Test.T)+b)\n",
    "\n",
    "m_Train =  x_Train.shape[0]\n",
    "m_Test =  x_Test.shape[0]\n",
    "\n",
    "y_Train_Prediction = Predict(final_Train_Prediction, m_Train)\n",
    "print('Train Accuracy',accuracy_score(y_Train_Prediction.T, y_Train))\n",
    "\n",
    "y_Test_Prediction = Predict(final_Test_Prediction, m_Test)\n",
    "print('Test Accuracy',accuracy_score(y_Test_Prediction.T, y_Train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-b)i. (1 mark) What is the logistic model P(ˆy = 1|x1, x2) and its cross-entropy error function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic model-P(ˆy = 1|x1, x2): [0.47726569 0.4192142  0.47539489 0.58285389 0.63679954 0.59844738]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "w=[1.5,0.5]\n",
    "b=-1\n",
    "logistic_model = Sigmoid(np.dot(w,x_Train.T)+b)\n",
    "print(\"Logistic model-P(ˆy = 1|x1, x2):\",logistic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic model-P(ˆy = 1|x1, x2)-entropy loss: 4.24695047852859\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "w=[1.5,0.5]\n",
    "b=-1\n",
    "m=x_Train.shape[0]\n",
    "cost = (-1/m)*(np.sum((y_Train*np.log(logistic_model)) + ((1-y_Train)*(np.log(1-logistic_model)))))\n",
    "print(\"Logistic model-P(ˆy = 1|x1, x2)-entropy loss:\",cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b) ii. (1 mark) Use gradient descent to update θ0, θ1, θ2 for one iteration. Write down the updated logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized weights [[1.50535086 0.50196867]]\n",
      "Optimized intercept -1.0031662597725644\n",
      "Train Accuracy 1.0\n",
      "Test Accuracy 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "w=[1.5,0.5]\n",
    "b=-1\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "n_features = x_Train.shape[1]\n",
    "\n",
    "\n",
    "coefficient, gradient, costs,W = Model_Prediction(w, b, x_Train, y_Train, learning_rate=0.1,no_iterations=1)\n",
    "\n",
    "\n",
    "\n",
    "w = coefficient[\"w\"]\n",
    "b = coefficient[\"b\"]\n",
    "\n",
    "print('Optimized weights', w)\n",
    "print('Optimized intercept',b)\n",
    "\n",
    "final_Train_Prediction = Sigmoid(np.dot(w,x_Train.T)+b)\n",
    "final_Test_Prediction = Sigmoid(np.dot(w,x_Test.T)+b)\n",
    "\n",
    "m_Train =  x_Train.shape[0]\n",
    "m_Test =  x_Test.shape[0]\n",
    "\n",
    "y_Train_Prediction = Predict(final_Train_Prediction, m_Train)\n",
    "print('Train Accuracy',accuracy_score(y_Train_Prediction.T, y_Train))\n",
    "\n",
    "y_Test_Prediction = Predict(final_Test_Prediction, m_Test)\n",
    "print('Test Accuracy',accuracy_score(y_Test_Prediction.T, y_Train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-c) iii. (2 mark) At convergence of gradient descent, use the model to make predictions for all the samples in the Test dataset. Calculate and report the accuracy, precision and recall to evaluate this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized weights [[31.36347263  7.53262099]]\n",
      "Optimized intercept -21.190551572578155\n",
      "Train Accuracy 1.0\n",
      "Test Accuracy 0.6666666666666666\n",
      "precision 0.6\n",
      "recall 1.0\n"
     ]
    }
   ],
   "source": [
    "w=[1.5,0.5]\n",
    "b=-1\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "\n",
    "n_features = x_Train.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "coefficient, gradient, costs,W = Model_Prediction(w, b, x_Train, y_Train, learning_rate=0.1,no_iterations=100000)\n",
    "\n",
    "\n",
    "w = coefficient[\"w\"]\n",
    "b = coefficient[\"b\"]\n",
    "\n",
    "print('Optimized weights', w)\n",
    "print('Optimized intercept',b)\n",
    "\n",
    "final_Train_prediciton = Sigmoid(np.dot(w,x_Train.T)+b)\n",
    "final_Test_Prediction = Sigmoid(np.dot(w,x_Test.T)+b)\n",
    "\n",
    "m_Train =  x_Train.shape[0]\n",
    "m_Test =  x_Test.shape[0]\n",
    "\n",
    "y_Train_Prediction = Predict(final_Train_Prediction, m_Train)\n",
    "print('Train Accuracy',accuracy_score(y_Train_Prediction.T, y_Train))\n",
    "\n",
    "y_Test_Prediction = Predict(final_Test_Prediction, m_Test)\n",
    "print('Test Accuracy',accuracy_score(y_Test_Prediction.T, y_Train))\n",
    "print('precision',precision_score(y_Test,y_Test_Prediction.T))\n",
    "print('recall',recall_score(y_Test,y_Test_Prediction.T))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
