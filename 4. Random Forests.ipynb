{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('https://web.stanford.edu/~hastie/ElemStatLearn//datasets/spam.data'), sep = ' ', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>col_48</th>\n",
       "      <th>col_49</th>\n",
       "      <th>col_50</th>\n",
       "      <th>col_51</th>\n",
       "      <th>col_52</th>\n",
       "      <th>col_53</th>\n",
       "      <th>col_54</th>\n",
       "      <th>col_55</th>\n",
       "      <th>col_56</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.142</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.404</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.147</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      col_0  col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9  \\\n",
       "0      0.00   0.64   0.64    0.0   0.32   0.00   0.00   0.00   0.00   0.00   \n",
       "1      0.21   0.28   0.50    0.0   0.14   0.28   0.21   0.07   0.00   0.94   \n",
       "2      0.06   0.00   0.71    0.0   1.23   0.19   0.19   0.12   0.64   0.25   \n",
       "3      0.00   0.00   0.00    0.0   0.63   0.00   0.31   0.63   0.31   0.63   \n",
       "4      0.00   0.00   0.00    0.0   0.63   0.00   0.31   0.63   0.31   0.63   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "4596   0.31   0.00   0.62    0.0   0.00   0.31   0.00   0.00   0.00   0.00   \n",
       "4597   0.00   0.00   0.00    0.0   0.00   0.00   0.00   0.00   0.00   0.00   \n",
       "4598   0.30   0.00   0.30    0.0   0.00   0.00   0.00   0.00   0.00   0.00   \n",
       "4599   0.96   0.00   0.00    0.0   0.32   0.00   0.00   0.00   0.00   0.00   \n",
       "4600   0.00   0.00   0.65    0.0   0.00   0.00   0.00   0.00   0.00   0.00   \n",
       "\n",
       "      ...  col_48  col_49  col_50  col_51  col_52  col_53  col_54  col_55  \\\n",
       "0     ...   0.000   0.000     0.0   0.778   0.000   0.000   3.756      61   \n",
       "1     ...   0.000   0.132     0.0   0.372   0.180   0.048   5.114     101   \n",
       "2     ...   0.010   0.143     0.0   0.276   0.184   0.010   9.821     485   \n",
       "3     ...   0.000   0.137     0.0   0.137   0.000   0.000   3.537      40   \n",
       "4     ...   0.000   0.135     0.0   0.135   0.000   0.000   3.537      40   \n",
       "...   ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "4596  ...   0.000   0.232     0.0   0.000   0.000   0.000   1.142       3   \n",
       "4597  ...   0.000   0.000     0.0   0.353   0.000   0.000   1.555       4   \n",
       "4598  ...   0.102   0.718     0.0   0.000   0.000   0.000   1.404       6   \n",
       "4599  ...   0.000   0.057     0.0   0.000   0.000   0.000   1.147       5   \n",
       "4600  ...   0.000   0.000     0.0   0.125   0.000   0.000   1.250       5   \n",
       "\n",
       "      col_56  label  \n",
       "0        278      1  \n",
       "1       1028      1  \n",
       "2       2259      1  \n",
       "3        191      1  \n",
       "4        191      1  \n",
       "...      ...    ...  \n",
       "4596      88      0  \n",
       "4597      14      0  \n",
       "4598     118      0  \n",
       "4599      78      0  \n",
       "4600      40      0  \n",
       "\n",
       "[4601 rows x 58 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "col = {}\n",
    "for k in df.columns:\n",
    "    if k == 57:\n",
    "        col[k] = 'label'\n",
    "    else:\n",
    "        col[k] = 'col_'+str(k) \n",
    "\n",
    "data = df.rename(columns = col)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def TrainTestSplit(df, TestSize):\n",
    "    \n",
    "    if isinstance(TestSize, float):\n",
    "        TestSize = round(TestSize * len(df))\n",
    "\n",
    "    indices = df.index.tolist()\n",
    "    test_indices = random.sample(population=indices, k=TestSize)\n",
    "\n",
    "    Test = df.loc[test_indices] \n",
    "    Train = df.drop(test_indices) \n",
    "    \n",
    "    return Train, Test  \n",
    "\n",
    "\n",
    "def FindFeatureType(df):\n",
    "    \n",
    "    type_of_cols = []\n",
    "    tresholdOfUniqueValue = 15\n",
    "    for feature in df.columns:\n",
    "        if feature != \"label\":\n",
    "            unique_values = df[feature].unique()\n",
    "            example_value = unique_values[0]\n",
    "\n",
    "            if (isinstance(example_value, str)) or (len(unique_values) <= tresholdOfUniqueValue):\n",
    "                type_of_cols.append(\"categorical\")\n",
    "            else:\n",
    "                type_of_cols.append(\"continuous\")\n",
    "    \n",
    "    return type_of_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ispure(data):\n",
    "    \n",
    "    target = data[:, -1]\n",
    "    uniqueVal = np.unique(target)\n",
    "\n",
    "    if len(uniqueVal) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    \n",
    "def val_classify(data):\n",
    "    \n",
    "    target = data[:, -1]\n",
    "    uniqueVal, counts_uniqueVal = np.unique(target, return_counts=True)\n",
    "\n",
    "    index = counts_uniqueVal.argmax()\n",
    "    classify = uniqueVal[index]\n",
    "    \n",
    "    return classify\n",
    "\n",
    "\n",
    "def unique_values_cols(data, random_subspace):\n",
    "    \n",
    "    split_values_cols = {}\n",
    "    _, n_columns = data.shape\n",
    "    column_indices = list(range(n_columns - 1))    \n",
    "    \n",
    "    if random_subspace and random_subspace <= len(column_indices):\n",
    "        column_indices = random.sample(population=column_indices, k=random_subspace)\n",
    "    \n",
    "    for col_idx in column_indices:          \n",
    "        values = data[:, col_idx]\n",
    "        unique_values = np.unique(values)\n",
    "        \n",
    "        split_values_cols[col_idx] = unique_values\n",
    "    \n",
    "    return split_values_cols\n",
    "\n",
    "\n",
    "\n",
    "def Entropy(data):\n",
    "    \n",
    "    target = data[:, -1]\n",
    "    _, counts = np.unique(target, return_counts=True)\n",
    "\n",
    "    prob = counts / counts.sum()\n",
    "    entropy = sum(prob * -np.log2(prob))\n",
    "     \n",
    "    return entropy\n",
    "\n",
    "\n",
    "def cal_complete_entropy(LeftData, RightData):\n",
    "    \n",
    "    n = len(LeftData) + len(RightData)\n",
    "    p_LeftData = len(LeftData) / n\n",
    "    p_RightData = len(RightData) / n\n",
    "\n",
    "    complete_entropy =  (p_LeftData * Entropy(LeftData) \n",
    "                      + p_RightData * Entropy(RightData))\n",
    "    \n",
    "    return complete_entropy\n",
    "\n",
    "\n",
    "def Best_Split(data, split_values_cols):\n",
    "    \n",
    "    complete_entropy = 9999\n",
    "    for col_idx in split_values_cols:\n",
    "        for value in split_values_cols[col_idx]:\n",
    "            LeftData, RightData = DataSplit(data, split_column=col_idx, split_value=value)\n",
    "            current_complete_entropy = cal_complete_entropy(LeftData, RightData)\n",
    "            \n",
    "            if current_complete_entropy <= complete_entropy:\n",
    "                complete_entropy = current_complete_entropy\n",
    "                BestSplitColumn = col_idx\n",
    "                BestSplitValue = value\n",
    "    \n",
    "    return BestSplitColumn,BestSplitValue\n",
    "\n",
    "def DataSplit(data, split_column, split_value):\n",
    "    \n",
    "    split_column_values = data[:, split_column]\n",
    "\n",
    "    type_of_feature = FEATURE_TYPES[split_column]\n",
    "    if type_of_feature == \"continuous\":\n",
    "        LeftData = data[split_column_values <= split_value]\n",
    "        RightData = data[split_column_values >  split_value]\n",
    "    \n",
    "     \n",
    "    else:\n",
    "        LeftData = data[split_column_values == split_value]\n",
    "        RightData = data[split_column_values != split_value]\n",
    "    \n",
    "    return LeftData, RightData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def DecisionTreeAlgorithm(df, count=0, min_samples=2, max_depth=5, random_subspace=None):\n",
    "    \n",
    "    \n",
    "    if count == 0:\n",
    "        global COLUMN_HEADERS, FEATURE_TYPES\n",
    "        COLUMN_HEADERS = df.columns\n",
    "        FEATURE_TYPES = FindFeatureType(df)\n",
    "        data = df.values\n",
    "    else:\n",
    "        data = df           \n",
    "    \n",
    "    \n",
    "    if (ispure(data)) or (len(data) < min_samples) or (count == max_depth):\n",
    "        classify = val_classify(data)\n",
    "        \n",
    "        return classify\n",
    "    \n",
    "   \n",
    "    else:    \n",
    "        count += 1\n",
    "\n",
    "         \n",
    "        split_values_cols = unique_values_cols(data, random_subspace)\n",
    "        split_column, split_value = Best_Split(data, split_values_cols)\n",
    "        LeftData, RightData = DataSplit(data, split_column, split_value)\n",
    "        \n",
    "        \n",
    "        if len(LeftData) == 0 or len(RightData) == 0:\n",
    "            classify = val_classify(data)\n",
    "            return classify\n",
    "        \n",
    "        \n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        type_of_feature = FEATURE_TYPES[split_column]\n",
    "        if type_of_feature == \"continuous\":\n",
    "            Question = \"{} <= {}\".format(feature_name, split_value)\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            Question = \"{} = {}\".format(feature_name, split_value)\n",
    "        \n",
    "        \n",
    "        SubTree = {Question: []}\n",
    "        \n",
    "       \n",
    "        conditionTrue = DecisionTreeAlgorithm(LeftData, count, min_samples, max_depth, random_subspace)\n",
    "        conditionFalse = DecisionTreeAlgorithm(RightData, count, min_samples, max_depth, random_subspace)\n",
    "        \n",
    "        \n",
    "        if conditionTrue == conditionFalse:\n",
    "            SubTree = conditionTrue\n",
    "        else:\n",
    "            SubTree[Question].append(conditionTrue)\n",
    "            SubTree[Question].append(conditionFalse)\n",
    "        \n",
    "        return SubTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ExamplePrediction(example, tree):\n",
    "    Question = list(tree.keys())[0]\n",
    "    feature_name, comp_Oper, value = Question.split(\" \")\n",
    "\n",
    "    \n",
    "    if comp_Oper == \"<=\":\n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[Question][0]\n",
    "        else:\n",
    "            answer = tree[Question][1]\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        if str(example[feature_name]) == value:\n",
    "            answer = tree[Question][0]\n",
    "        else:\n",
    "            answer = tree[Question][1]\n",
    "\n",
    "    \n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        ResidualTree = answer\n",
    "        return ExamplePrediction(example, ResidualTree)\n",
    "    \n",
    "\n",
    "def Prediction_of_decision_trees(test_df, tree):\n",
    "    predictions = test_df.apply(ExamplePrediction, args=(tree,), axis=1)\n",
    "    return predictions\n",
    "\n",
    "def OOb_score(pred, y_test):\n",
    "    wrong_label = 0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] != y_test[i]:\n",
    "            wrong_label += 1\n",
    "    return wrong_label / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "train_df, test_df = TrainTestSplit(data, TestSize=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BootStrapping_Samples(train_df, n_bootstrap):\n",
    "    bootstrappedIndices = np.random.randint(low=0, high=len(train_df), size=n_bootstrap)\n",
    "    df_bootstrapped = train_df.iloc[bootstrappedIndices]\n",
    "    df_oob = train_df.iloc[~bootstrappedIndices]    \n",
    "    return df_bootstrapped, df_oob\n",
    "\n",
    "\n",
    "def RandomForestAlgorithm(train_df, n_trees, n_bootstrap, n_features, dt_max_depth):\n",
    "    forest = []\n",
    "    OOB_data = []\n",
    "    OOB_score = []\n",
    "    for i in range(n_trees):\n",
    "        df_bootstrapped, df_oob = BootStrapping_Samples(train_df, n_bootstrap)\n",
    "        tree = DecisionTreeAlgorithm(df_bootstrapped, max_depth=dt_max_depth, random_subspace=n_features)\n",
    "        forest.append(tree)\n",
    "        \n",
    "        oob_pred = Prediction_of_decision_trees(df_oob, tree)\n",
    "        oob_predicted = [int(i) for i in oob_pred]\n",
    "        score = OOb_score(oob_predicted, df_oob.label.values)        \n",
    "        \n",
    "        OOB_score.append(score)\n",
    "    \n",
    "    return forest, np.mean(OOB_score)\n",
    "\n",
    "def PredictionsOfRandomForest(test_df, forest):\n",
    "    \n",
    "    df_predictions = {}\n",
    "    oob_pred_list = []\n",
    "    for i in range(len(forest)):\n",
    "        column_name = \"tree_{}\".format(i)\n",
    "        predictions = Prediction_of_decision_trees(test_df, tree=forest[i])\n",
    "        df_predictions[column_name] = predictions\n",
    "\n",
    "    df_predictions = pd.DataFrame(df_predictions)\n",
    "    #print(df_predictions.head())\n",
    "    PredictionsOfRandomForest = df_predictions.mode(axis=1)[0]\n",
    "    \n",
    "    return PredictionsOfRandomForest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training  my  own Random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 57.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "forest, Oob_estimate = RandomForestAlgorithm(train_df, n_trees=4, n_bootstrap=train_df.shape[0], n_features=30, dt_max_depth=4)\n",
    "predictions = PredictionsOfRandomForest(test_df, forest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluationMetric(y_true, y_pred):\n",
    "    from sklearn.metrics import accuracy_score, auc, confusion_matrix\n",
    "    acc = accuracy_score(test_df.label, predictions)\n",
    "    print(\"Accuracy = {}\".format(acc))\n",
    "    \n",
    "    cm1 = confusion_matrix(test_df.label, predictions)\n",
    "    sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    print(\"Sensitivity =\", sensitivity)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8521739130434782\n",
      "Sensitivity = 0.9789081885856079\n"
     ]
    }
   ],
   "source": [
    "EvaluationMetric(test_df, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot OOB error \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obb estimates for number of features 8 is 0.1341819310773052\n",
      "Obb estimates for number of features 18 is 0.10742005588326609\n",
      "Obb estimates for number of features 28 is 0.10984166407947842\n",
      "Obb estimates for number of features 38 is 0.10468798509779571\n",
      "Obb estimates for number of features 48 is 0.09810617820552624\n",
      "Obb estimates for number of features 57 is 0.10114871158025458\n",
      "Wall time: 6min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_features = [8,18,28,38,48,57]\n",
    "score = []\n",
    "for feat in n_features:\n",
    "    \n",
    "    forest, Obb_estimate = RandomForestAlgorithm(train_df, n_trees=5, n_bootstrap=train_df.shape[0], n_features=feat, dt_max_depth=4)\n",
    "    score.append(Obb_estimate)\n",
    "    print(\"Obb estimates for number of features {} is {}\".format(feat, Obb_estimate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e0893986d8>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(n_features, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features choosed:  8\n",
      "Accuracy = 0.8826086956521739\n",
      "Sensitivity = 0.9652605459057072\n",
      "---------\n",
      "Number of features choosed:  18\n",
      "Accuracy = 0.8695652173913043\n",
      "Sensitivity = 0.9143920595533499\n",
      "---------\n",
      "Number of features choosed:  28\n",
      "Accuracy = 0.894927536231884\n",
      "Sensitivity = 0.9751861042183623\n",
      "---------\n",
      "Number of features choosed:  38\n",
      "Accuracy = 0.8913043478260869\n",
      "Sensitivity = 0.9652605459057072\n",
      "---------\n",
      "Number of features choosed:  48\n",
      "Accuracy = 0.8905797101449275\n",
      "Sensitivity = 0.9503722084367245\n",
      "---------\n",
      "Number of features choosed:  57\n",
      "Accuracy = 0.8681159420289855\n",
      "Sensitivity = 0.9751861042183623\n",
      "---------\n",
      "Wall time: 52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_features = [8,18,28,38,48,57]\n",
    "for n_feat in n_features:\n",
    "    print(\"Number of features choosed: \", n_feat)\n",
    "     \n",
    "    forest, oob_estimate = RandomForestAlgorithm(train_df, n_trees=4, n_bootstrap=800, n_features=30, dt_max_depth=4)\n",
    "    \n",
    "    predictions = PredictionsOfRandomForest(test_df, forest)\n",
    "    \n",
    "    EvaluationMetric(test_df.label, predictions)\n",
    "    print(\"---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a Inbuilt random forest classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train_df.iloc[:,:-1], train_df.iloc[:,-1:]\n",
    "x_test, y_test =  test_df.iloc[:,:-1], test_df.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 442 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=4, random_state=0)\n",
    "clf.fit(x_train, y_train.label)\n",
    "pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8681159420289855\n",
      "Sensitivity = 0.9751861042183623\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EvaluationMetric(test_df.label, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
